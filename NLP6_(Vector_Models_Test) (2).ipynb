{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP6 (Vector Models Test)",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5IOCy0ZFe1-",
        "colab_type": "code",
        "outputId": "7a97e2ff-88b9-4fd9-baa4-6f09b3ff2ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') # grant access to google drive filesystem\n",
        "\n",
        "!pip3 install spacy\n",
        "!python3 -m spacy download es\n",
        "!python -m spacy download es_core_news_md\n",
        "!python -m spacy.es.download all\n",
        "#!pip install newspaper3k\n",
        "!pip install pandas --upgrade\n",
        "!pip install PyPrind\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.17.5)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.0.8)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy) (4.28.1)\n",
            "Collecting es_core_news_sm==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.1.0/es_core_news_sm-2.1.0.tar.gz (11.1MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1MB 1.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: es-core-news-sm\n",
            "  Building wheel for es-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for es-core-news-sm: filename=es_core_news_sm-2.1.0-cp36-none-any.whl size=11111557 sha256=d92ac551d35b9c12f34097660b908c6c719662cb7eeba6a6266e071acda52a29\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dgc2cjba/wheels/cc/ee/c4/68922955901918a9aaa82e828d4f7ee1ccfc861285277e79b7\n",
            "Successfully built es-core-news-sm\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/es_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/es\n",
            "You can now load the model via spacy.load('es')\n",
            "Collecting es_core_news_md==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-2.1.0/es_core_news_md-2.1.0.tar.gz (73.4MB)\n",
            "\u001b[K     |████████████████████████████████| 73.4MB 1.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: es-core-news-md\n",
            "  Building wheel for es-core-news-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for es-core-news-md: filename=es_core_news_md-2.1.0-cp36-none-any.whl size=74602272 sha256=4d61de7a3bc802ccff87086f6b1bcfcec0b8ca342513ebae8c8841e409527751\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gtxmg_yk/wheels/20/f7/6b/7a1ba56f009b05386d123ea088b56635594a046acd5cfdd2a2\n",
            "Successfully built es-core-news-md\n",
            "Installing collected packages: es-core-news-md\n",
            "Successfully installed es-core-news-md-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_md')\n",
            "/usr/bin/python3: Error while finding module specification for 'spacy.es.download' (ModuleNotFoundError: No module named 'spacy.es')\n",
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Collecting PyPrind\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/30/e76fb0c45da8aef49ea8d2a90d4e7a6877b45894c25f12fb961f009a891e/PyPrind-2.11.2-py3-none-any.whl\n",
            "Installing collected packages: PyPrind\n",
            "Successfully installed PyPrind-2.11.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODZ9gOy1Fymd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim \n",
        "import spacy\n",
        "import os\n",
        "from gensim.models import KeyedVectors\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import pyprind\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB-tgu8gK6GG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/gdrive/My Drive/datos/verbs/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N58iYZDGbHH",
        "colab_type": "code",
        "outputId": "84405b97-b400-4ce6-c004-008891ed19b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "# Use only one group (actual training)\n",
        "\n",
        "#!python -m spacy init-model es '/content/gdrive/My Drive/datos/verbs/' --vectors-loc adnpolitico_model.txt.gz\n",
        "#nlp_adnpolitico = spacy.load(os.path.join(path))\n",
        "\n",
        "!python -m spacy init-model es \"/content/gdrive/My Drive/datos/verbs/\" --vectors-loc expansion_model.txt.gz \n",
        "nlp_expansion = spacy.load(os.path.join(path)) \n",
        "\n",
        "#!python -m spacy init-model es \"/content/gdrive/My Drive/datos/verbs/\" --vectors-loc lifeandstyle_model.txt.gz\n",
        "#nlp_lifeandstyle = spacy.load(os.path.join(path)) \n",
        "\n",
        "#!python -m spacy init-model es \"/content/gdrive/My Drive/datos/verbs/\" --vectors-loc manufactura_model.txt.gz \n",
        "#nlp_manufactura = spacy.load(os.path.join(path)) \n",
        "\n",
        "#!python -m spacy init-model es \"/content/gdrive/My Drive/datos/verbs/\" --vectors-loc obras_model.txt.gz \n",
        "#nlp_obras = spacy.load(os.path.join(path)) \n",
        "\n",
        "#!python -m spacy init-model es \"/content/gdrive/My Drive/datos/verbs/\" --vectors-loc quien_model.txt.gz\n",
        "#nlp_quien = spacy.load(os.path.join(path))\n",
        "\n",
        "#!python -m spacy init-model es \"/content/gdrive/My Drive/datos/verbs/\" --vectors-loc todos_model.txt.gz\n",
        "#nlp_todos = spacy.load(os.path.join(path))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[2K\u001b[38;5;2m✔ Successfully created model\u001b[0m\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/spacy/__main__.py\", line 35, in <module>\n",
            "    plac.call(commands[command], sys.argv[1:])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/plac_core.py\", line 328, in call\n",
            "    cmd, result = parser.consume(arglist)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/plac_core.py\", line 207, in consume\n",
            "    return cmd, self.func(*(args + varargs + extraopts), **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/spacy/cli/init_model.py\", line 82, in init_model\n",
            "    add_vectors(nlp, vectors_loc, prune_vectors)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/spacy/cli/init_model.py\", line 171, in add_vectors\n",
            "    vectors_data, vector_keys = read_vectors(vectors_loc)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/spacy/cli/init_model.py\", line 189, in read_vectors\n",
            "    f = open_file(vectors_loc)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/spacy/cli/init_model.py\", line 98, in open_file\n",
            "    if tarfile.is_tarfile(str(loc)):\n",
            "  File \"/usr/lib/python3.6/tarfile.py\", line 2450, in is_tarfile\n",
            "    t = open(name)\n",
            "  File \"/usr/lib/python3.6/tarfile.py\", line 1571, in open\n",
            "    return func(name, \"r\", fileobj, **kwargs)\n",
            "  File \"/usr/lib/python3.6/tarfile.py\", line 1636, in gzopen\n",
            "    fileobj = gzip.GzipFile(name, mode + \"b\", compresslevel, fileobj)\n",
            "  File \"/usr/lib/python3.6/gzip.py\", line 163, in __init__\n",
            "    fileobj = self.myfileobj = builtins.open(filename, mode or 'rb')\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'expansion_model.txt.gz'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0fa42c0238c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python -m spacy init-model es \"/content/gdrive/My Drive/datos/verbs/\" --vectors-loc expansion_model.txt.gz '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnlp_expansion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#!python -m spacy init-model es \"/content/gdrive/My Drive/datos/verbs/\" --vectors-loc lifeandstyle_model.txt.gz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# path to model data directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, **overrides)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(self, path, exclude, disable)\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;31m# Convert to list here in case exclude is (default) tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0mexclude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(path, readers, exclude)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;31m# Split to support file names like meta.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m             \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    821\u001b[0m         ) and _fix_pretrained_vectors_name(self)\n\u001b[1;32m    822\u001b[0m         deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(\n\u001b[0;32m--> 823\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m         )\n\u001b[1;32m    825\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.from_disk\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.from_bytes\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/re.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;34m\"Compile a regular expression pattern, returning a pattern object.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpurge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, pattern)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0;32m--> 416\u001b[0;31m                            not nested and not items))\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    525\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\\\\\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                     \u001b[0mcode1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_escape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0mcode1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLITERAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/sre_parse.py\u001b[0m in \u001b[0;36m_class_escape\u001b[0;34m(source, escape)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mASCIILETTERS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bad escape %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mescape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLITERAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: bad escape \\p at position 275"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIR7TfcIKv69",
        "colab_type": "code",
        "outputId": "458e1ade-2945-42e2-f72e-ed241419de97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Load word vectors\n",
        "\n",
        "wvAdnpolitico = KeyedVectors.load_word2vec_format(os.path.join(path, 'adnpolitico_model.txt'), binary=False) \n",
        "wvExpansion = KeyedVectors.load_word2vec_format(os.path.join(path, 'expansion_model.txt'), binary=False) \n",
        "wvLifeandstyle = KeyedVectors.load_word2vec_format(os.path.join(path, 'lifeandstyle_model.txt'), binary=False) \n",
        "wvManufactura = KeyedVectors.load_word2vec_format(os.path.join(path, 'manufactura_model.txt'), binary=False) \n",
        "wvObras = KeyedVectors.load_word2vec_format(os.path.join(path, 'obras_model.txt'), binary=False) \n",
        "wvQuien = KeyedVectors.load_word2vec_format(os.path.join(path, 'quien_model.txt'), binary=False) \n",
        "wvTodos = KeyedVectors.load_word2vec_format(os.path.join(path, 'todos_model.txt'), binary=False) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuYDjUmYdKM9",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "w1 = 'kim' # Palabra a buscar #✅\n",
        "nTop = 10 # Número de términos a reportar\n",
        "\n",
        "df = pd.Series(range(nTop))\n",
        "df = pd.DataFrame(columns=['n#'])\n",
        "\n",
        "if w1 in wvTodos.vocab:\n",
        "    ndf = pd.DataFrame(wvTodos.most_similar (positive=w1,topn=nTop), columns=['ALLv', 'ALL%'])\n",
        "else:\n",
        "    ndf = pd.DataFrame(columns=['ALLv', 'ALL%'])\n",
        "df = pd.concat([df, ndf], axis=1)\n",
        "    \n",
        "if w1 in wvAdnpolitico.vocab:\n",
        "    ndf = pd.DataFrame(wvAdnpolitico.most_similar (positive=w1,topn=nTop), columns=['ADNv', 'ADN%'])\n",
        "else:\n",
        "    ndf = pd.DataFrame(columns=['ADNv', 'ADN%'])\n",
        "df = pd.concat([df, ndf], axis=1)\n",
        "\n",
        "if w1 in wvExpansion.vocab:\n",
        "    ndf = pd.DataFrame(wvExpansion.most_similar (positive=w1,topn=nTop), columns=['EXPv', 'EXP%'])\n",
        "else:\n",
        "    ndf = pd.DataFrame(columns=['EXPv', 'EXP%'])\n",
        "df = pd.concat([df, ndf], axis=1)\n",
        "\n",
        "if w1 in wvLifeandstyle.vocab:\n",
        "    ndf = pd.DataFrame(wvLifeandstyle.most_similar (positive=w1,topn=nTop), columns=['LASv', 'LAS%'])\n",
        "else:\n",
        "    ndf = pd.DataFrame(columns=['LASv', 'LAS%'])\n",
        "df = pd.concat([df, ndf], axis=1)\n",
        "\n",
        "if w1 in wvManufactura.vocab:\n",
        "    ndf = pd.DataFrame(wvManufactura.most_similar (positive=w1,topn=nTop), columns=['MANv', 'MAN%'])\n",
        "else:\n",
        "    ndf = pd.DataFrame(columns=['MANv', 'MAN%'])\n",
        "df = pd.concat([df, ndf], axis=1)\n",
        "\n",
        "if w1 in wvObras.vocab:\n",
        "    ndf = pd.DataFrame(wvObras.most_similar (positive=w1,topn=nTop), columns=['OBRv', 'OBR%'])\n",
        "else:\n",
        "    ndf = pd.DataFrame(columns=['OBRv', 'OBR%'])\n",
        "df = pd.concat([df, ndf], axis=1)\n",
        "\n",
        "if w1 in wvQuien.vocab:\n",
        "    ndf = pd.DataFrame(wvQuien.most_similar (positive=w1,topn=nTop), columns=['QUIv', 'QUI%'])\n",
        "else:\n",
        "    ndf = pd.DataFrame(columns=['QUIv', 'QUI%'])\n",
        "df = pd.concat([df, ndf], axis=1)\n",
        "\n",
        "del df['n#']\n",
        "\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCSUqXH6S_FP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wvTodos.similarity(w1=\"cdmx\",w2=\"capital\") #✅"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i66WujJSKYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = ['pemex','romero','amlo'] #✅\n",
        "\n",
        "wvTodos.most_similar (positive=w1, topn=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFB4cg7gTw9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wvExpansion.doesnt_match(['méxico','guatemala','india', 'belice', 'argentina']) #✅"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz0dPolm1TKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wvTodos.closer_than(\"spotify\",\"apple\")#✅"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9wFMyMHpOAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rey - hombre + mujer = reina\n",
        "wvTodos.most_similar_cosmul(positive=['rey', 'mujer'], negative=['hombre']) #✅"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtITt82v6hxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wvTodos.get_vector(\"cdmx\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynofDtd3M6E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\"\n",
        "Document distance - Word Mover's Distance (WMD)\n",
        "\n",
        "WMD is a method that allows us to assess the \"distance\" between \n",
        "two documents in a meaningful way, even when they have no words \n",
        "in common. It uses word2vec vector embeddings of words. It \n",
        "been shown to outperform many of the state-of-the-art methods in \n",
        "k-nearest neighbors classification.\n",
        "\n",
        "Basado en \"From Word embeddings To Document Distances\"\n",
        "    Matt J. Kusner, Yu Sun, Nicholas I. Kolkin, Kilian Q. Weinberger\n",
        "    Washington University in St. Louis 2015.\n",
        "\"\"\"\"\"\n",
        "\n",
        "#frase1 = 'el gobierno de Trump ha ejercido presión sobre los países \\\n",
        "#        de todo el mundo para que no utilicen los equipos de Huawei'\n",
        "\n",
        "#frase2 = 'estados unidos no promueve el uso de teléfonos Huawei en todo el mundo'\n",
        "\n",
        "frase1 = 'las temperaturas altas en cdmx me dan flojera'\n",
        "\n",
        "frase2 = 'hace calor en la cdmx y no dan ganas de salir a trabajar'\n",
        "\n",
        "frase1 = frase1.lower().split()\n",
        "frase2 = frase2.lower().split()\n",
        "\n",
        "wvTodos.init_sims(replace=True)  # Normalizes the vectors in the word2vec class.\n",
        "distance = wvTodos.wmdistance(frase1, frase2)\n",
        "print('Todos: ', distance)\n",
        "\n",
        "wvExpansion.init_sims(replace=True)\n",
        "distance = wvExpansion.wmdistance(frase1, frase2)\n",
        "print('Expansion: ', distance)\n",
        "\n",
        "wvQuien.init_sims(replace=True)\n",
        "distance = wvQuien.wmdistance(frase1, frase2)\n",
        "print('Quien: ', distance)\n",
        "\n",
        "wvLifeandstyle.init_sims(replace=True)\n",
        "distance = wvLifeandstyle.wmdistance(frase1, frase2)\n",
        "print('Life and Style: ', distance)\n",
        "\n",
        "wvObras.init_sims(replace=True)\n",
        "distance = wvObras.wmdistance(frase1, frase2)\n",
        "print('Obras: ', distance)\n",
        "\n",
        "wvAdnpolitico.init_sims(replace=True)\n",
        "distance = wvAdnpolitico.wmdistance(frase1, frase2)\n",
        "print('ADN Politico: ', distance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzHhGBVZSNKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute distance between a percentage articles in dataset\n",
        "\n",
        "percentage = 0.1 # (ajustar este valor para controlar tiempo, depende del sitio elegido en la celda anterior)\n",
        "\n",
        "dfResult = pd.DataFrame()\n",
        "cols = ['dist', 'urlA', 'urlB']\n",
        "wvObras.init_sims(replace=True)\n",
        "dfA = df.sample(frac=percentage)\n",
        "dfB = df.sample(frac=percentage)\n",
        "count = len(dfA) * len(dfB)\n",
        "perc = pyprind.ProgPercent(count)\n",
        "with open(os.path.join(path, 'dfResult.csv'), 'w') as csvfile:\n",
        "    wr = csv.writer(csvfile)\n",
        "    wr.writerow(['distance', 'urlA', 'urlB'])\n",
        "    for indexI, rowI in dfA.iterrows(): # for each article\n",
        "        texto1 = rowI['texto'].lower().split()\n",
        "        for indexJ, rowJ in dfB.iterrows(): # for each article\n",
        "            texto2 = rowJ['texto'].lower().split()\n",
        "            distance = wvTodos.wmdistance(texto1, texto2)\n",
        "            if distance > 0:\n",
        "                dfResult = dfResult.append(pd.DataFrame({'dist': distance,'urlA': rowI['url'], 'urlB': rowJ['url']}, index=[0]))\n",
        "                wr = csv.writer(csvfile)\n",
        "                wr.writerow([distance, rowI['url'], rowJ['url']])\n",
        "                #print(distance, rowI['url'], rowJ['url']) \n",
        "            perc.update() # signal to increment the progress %\n",
        "\n",
        "print(\"\\n\")\n",
        "print(*dfResult.sort_values(by='dist').values.tolist(),sep = \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsENY_JeHUIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test similarity between articles in dataset\n",
        "\n",
        "path = '/content/gdrive/My Drive/datos/'\n",
        "notesFile = u'content.csv'\n",
        "\n",
        "with open(os.path.join(path, notesFile)) as csv_file:\n",
        "    df = pd.read_csv(os.path.join(path, notesFile))\n",
        "    \n",
        "# remove records with null 'texto' and null 'url'\n",
        "df = df.loc[df['texto'] == df['texto']]\n",
        "df = df.loc[df['url'] == df['url']]\n",
        "\n",
        "#filter by sitio\n",
        "#df = df.loc[df['sitio'] == 'Quién']\n",
        "\n",
        "df.set_index('url')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No3u7sesAUG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute distance between ONE text and the rest of the dataset\n",
        "\n",
        "percentage = 1 # (ajustar este valor para controlar tiempo, depende del sitio elegido en la celda anterior)\n",
        "\n",
        "oneText = 'un mariachi irrumpio en la conferencia mananera del presidente andres manuel lopez obrador para cantar las mananitas a las madres en este 10 de mayo de acuerdo a reforma, al terminar la conferencia, el mandatario federal dijo que iniciaria el festejo a las mamas, y entro el mariachi al salon tesoreria de palacio nacional. cantaron las mananitas y despues hermoso carino, mujeres divinas y amor eterno. entre las asistentes estuvieron la clavadista paola espinosa y elena poniatowska. el presidente deseo felicidades a las mamas que estan en mexico y otros paises, como estados unidos. a todas las mamas felicidades, que no falte nadie, las mamas que estan en otros paises, las que estan viviendo en estados unidos, en otros paises, y a todas las mamas que viven en mexico felicidades dijo lopez obrador. si alguna de las mamas de este ramillete de mamas que esta aqui, que es una representacion de todas las madres de mexico, si alguna quiere tomar la palabra que lo haga, convoco. algunas de las invitadas tomaron la palabra para agradecer el festejo. elena poniatowska recordo a su madre. mira mama, yo creo que has de estar muy contenta, has de estar sintiendo que mexico ha cambiado mucho, que mexico va por un camino que nunca tu recorriste con los presidentes anteriores. mira mama, creo que somos muy felices aqui en este dia entre mariachis y tantos corazones que nos acompanan. en su oportunidad, la clavadista espinosa dijo que es dificil que como mamas regresen a destacar en el ambito deportivo, pero adelanto que volvera a buscar una medalla en los proximos juegos olimpicos.'\n",
        "\n",
        "dfResult = pd.DataFrame()\n",
        "cols = ['dist', 'urlA', 'urlB']\n",
        "wvObras.init_sims(replace=True)\n",
        "dfA = df.sample(frac=percentage)\n",
        "count = len(dfA) #* len(dfB)\n",
        "perc = pyprind.ProgPercent(count)\n",
        "with open(os.path.join(path, 'dfResult.csv'), 'w') as csvfile:\n",
        "    wr = csv.writer(csvfile)\n",
        "    wr.writerow(['distance', 'urlA', 'urlB'])\n",
        "    for indexI, rowI in dfA.iterrows(): # for each article\n",
        "        texto1 = rowI['texto'].lower().split()\n",
        "        distance = wvTodos.wmdistance(texto1, oneText)\n",
        "        if distance > 0:\n",
        "            dfResult = dfResult.append(pd.DataFrame({'dist': distance,'urlA': rowI['url']}, index=[0]))\n",
        "            wr = csv.writer(csvfile)\n",
        "            wr.writerow([distance, rowI['url']])\n",
        "            #print(distance, rowI['url'], rowJ['url']) \n",
        "        perc.update() # signal to increment the progress %\n",
        "\n",
        "print(\"\\n\")\n",
        "print(*dfResult.sort_values(by='dist').values.tolist(),sep = \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooSgGK0he4Wn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(*dfResult.sort_values(by='dist').values.tolist(),sep = \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}